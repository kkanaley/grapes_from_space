{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c3524ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "#import statannotations\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import imblearn as imb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import scipy\n",
    "\n",
    "import rioxarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b3442e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps_20230616 = rioxarray.open_rasterio(\n",
    "#     \"/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2020/PScope/dis_band_2020/20200616_151605_21_2304_3B_AnalyticMS_SR_8b_harmonized_clip_clipped.tif_disease.tif\",\n",
    "# )\n",
    "# ps_20230616.name = 'ps_20230616'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc8f9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pscope_df = ps_20230616.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c892366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pscope_df['ps_20230616']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcabe88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = '/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2020/PScope/dis_band_2020/20200616_151605_21_2304_3B_AnalyticMS_SR_8b_harmonized_clip_clipped.tif_disease.tif'\n",
    "with rio.open(image) as src:\n",
    "        raster_arr = np.array(src.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3450ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 22, 41)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d461e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_class = raster_arr[10]*1000\n",
    "sev_class = raster_arr[9]*1000\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b07e153e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a5e8a82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 41)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_class = (inc_class > 25).astype(int)\n",
    "inc_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a25575e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 41)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sev_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8c034c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try adding the severity and incidence classifications as bands to the dis_rasters\n",
    "\n",
    "def add_classes(image, inc_band, sev_band) :\n",
    "    '''Adds bands for severity and incidence classifications.\n",
    "    \"high\" is coded as a 1\n",
    "    \"low\" is coded as a 0\n",
    "    \n",
    "    image: (string) path to raster \n",
    "    inc_band: (int) band containing incidence values\n",
    "    sev_band: (int) band containing severity values\n",
    "    \n",
    "    returns: array with original image bands + incidence and severity class bands\n",
    "    '''\n",
    "    \n",
    "    with rio.open(image) as src:\n",
    "        raster_arr = np.array(src.read())\n",
    "        raster_arr = raster_arr\n",
    "        \n",
    "        inc_class = raster_arr[inc_band]\n",
    "        sev_class = raster_arr[sev_band]\n",
    "        \n",
    "        # if incidence > 25%, enter \"1\", else \"0\"\n",
    "        inc_class = (inc_class > 25).astype(int)\n",
    "        \n",
    "        # if severity > 10%, enter \"1\", else \"0\"\n",
    "        sev_class = (sev_class > 10).astype(int)\n",
    "        \n",
    "        stacked_arr = np.vstack([raster_arr,\n",
    "                                 inc_class.reshape(1,raster_arr.shape[1],raster_arr.shape[2]),\n",
    "                                 sev_class.reshape(1,raster_arr.shape[1],raster_arr.shape[2])])\n",
    "    \n",
    "    # Save stacked array as raster\n",
    "    with rio.open(image) as src:\n",
    "        kwargs = src.meta\n",
    "        band_ct = stacked_arr.shape[0]\n",
    "        kwargs.update(dtype=rio.float32, count=band_ct)\n",
    "        \n",
    "        with rio.open(str(os.path.split(image)[0])+'/inc_sev_class_'+str(os.path.basename(image)), 'w', **kwargs) as dst:\n",
    "            for b in range(stacked_arr.shape[0]):\n",
    "                dst.write_band(b+1, stacked_arr[b].astype(rio.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec2271b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2020/PScope/dis_band_2020/20200801_151354_03_2212_3B_AnalyticMS_SR_8b_harmonized_clip_clipped.tif_disease.tif',\n",
       " '/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2020/PScope/dis_band_2020/20200713_151457_44_2278_3B_AnalyticMS_SR_8b_harmonized_clip_clipped.tif_disease.tif',\n",
       " '/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2020/PScope/dis_band_2020/20200616_151605_21_2304_3B_AnalyticMS_SR_8b_harmonized_clip_clipped.tif_disease.tif']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function with 2020 PScope dis band images\n",
    "\n",
    "ps_2020 = glob.glob('/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2020/PScope/dis_band_2020/20*.tif')\n",
    "ps_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b6a32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in ps_2020:\n",
    "    add_classes(img, inc_band=10, sev_band=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d578401d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2021/PScope/dis_band_2021/20210808_150651_57_2460_3B_AnalyticMS_SR_8b_harmonized_clip_clipped.tif_disease.tif',\n",
       " '/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2021/PScope/dis_band_2021/20210804_152058_95_222f_3B_AnalyticMS_SR_8b_harmonized_clip_clipped.tif_disease.tif',\n",
       " '/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2021/PScope/dis_band_2021/20210726_155527_27_227a_3B_AnalyticMS_SR_8b_harmonized_clip_clipped.tif_disease.tif',\n",
       " '/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2021/PScope/dis_band_2021/20210715_151038_58_2450_3B_AnalyticMS_SR_8b_harmonized_clip_clipped.tif_disease.tif']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_2021 = glob.glob('/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2021/PScope/dis_band_2021/20*.tif')\n",
    "ps_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2c5797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in ps_2021:\n",
    "    add_classes(img, inc_band=10, sev_band=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "357564f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2022/PScope/dis_band_2022/20220726_155410_80_2407_3B_AnalyticMS_SR_8b_clipped_clipped.tif_disease.tif',\n",
       " '/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2022/PScope/dis_band_2022/20220801_150200_56_245c_3B_AnalyticMS_SR_8b_harmonized_clip_clipped.tif_disease.tif',\n",
       " '/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2022/PScope/dis_band_2022/20220828_151645_10_2262_3B_AnalyticMS_SR_8b_harmonized_clip_clipped.tif_disease.tif',\n",
       " '/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2022/PScope/dis_band_2022/20220630_150422_85_241d_3B_AnalyticMS_SR_8b_clipped_clipped.tif_disease.tif',\n",
       " '/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2022/PScope/dis_band_2022/20220704_155057_15_240a_3B_AnalyticMS_SR_8b_clipped_clipped.tif_disease.tif',\n",
       " '/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2022/PScope/dis_band_2022/20220624_150204_01_241b_3B_AnalyticMS_SR_8b_clipped_clipped.tif_disease.tif']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_2022 = glob.glob('/Users/kathleenkanaley/Desktop/grapes_from_space/data/images/2022/PScope/dis_band_2022/20*.tif')\n",
    "ps_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d1e8afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in ps_2022:\n",
    "    add_classes(img, inc_band=10, sev_band=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d285b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def img_to_df(img_path, cols):\n",
    "#     with rio.open(img_path) as src:\n",
    "#         as_array = src.read()\n",
    "#         band_arrs = []\n",
    "        \n",
    "#         for i in np.arange(src.count):\n",
    "#             band_arr = as_array[i].flatten()\n",
    "#             band_arr = band_arr/10000\n",
    "            \n",
    "#             band_arrs.append(band_arr)\n",
    "        \n",
    "#         df = pd.DataFrame(band_arrs,cols).T\n",
    "#         df['Date'] = img_path.split('/')[-1].split('_')[0]\n",
    "        \n",
    "#         # Optional: drops entries with no severity rating. Comment out if unnecessary.\n",
    "#         no_nans = df.dropna(subset=['total_dis_sev']) \n",
    "        \n",
    "#         return no_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02dab1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_vis(df):\n",
    "#     df['pri']= (df['green']- df['greenI'])/(df['green']+df['greenI'])\n",
    "#     df['ndre'] = (df['nir'] - df['rede']) / (df['nir'] + df['rede'])\n",
    "#     df['tcari'] = 3 * (( (df['rede'] - df['red']) - 0.2 * (df['rede'] - df['green']) ) * (df['rede'] / df['red']))\n",
    "#     df['ndvi']= (df['nir']-df['red'])/(df['nir']+df['red'])\n",
    "#     df['evi']= 2.5*(df['nir']-df['red'])/(df['nir']+6*df['red']-7.5*df['blue']+1)\n",
    "#     df['savi']= 1.5*(df['nir']-df['red'])/(df['nir']+df['red']+0.5)\n",
    "#     df['arvi']=(df['nir']-(2*df['red']-df['blue']))/(df['nir']+(2*df['red']-df['blue']))\n",
    "#     df['green_red'] = (df['green']-df['red'])/(df['green']+df['red'])\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79653ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '/Users/kathleenkanaley/Desktop/grapes_from_space/data/'\n",
    "# dis_ras_20 = glob.glob(data_dir +'images/2020/PScope/dis_band_*/*.tif')\n",
    "# dis_ras_21 = glob.glob(data_dir +'images/2021/PScope/dis_band_*/*.tif')\n",
    "# dis_ras_22 = glob.glob(data_dir +'images/2022/PScope/dis_band_*/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c45bc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['c_blue', 'blue', 'greenI', 'green', 'yellow', 'red', 'rede', 'nir',\n",
       "       'total_dis_sev', 'dm_sev', 'dm_inc', 'Date', 'inc_class',\n",
       "       'severity_class', 'pri', 'ndre', 'tcari', 'ndvi', 'evi', 'savi', 'arvi',\n",
       "       'green_red'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cols = ['c_blue','blue','greenI', 'green', 'yellow', 'red', 'rede', 'nir','total_dis_sev','dm_sev', 'dm_inc']\n",
    "\n",
    "# # 2020\n",
    "\n",
    "# dfs_2020 = [img_to_df(dis_ras_20[i], cols) for i in np.arange(len(dis_ras_20))]\n",
    "# df_2020 = pd.concat(dfs_2020)\n",
    "\n",
    "# df_2020['total_dis_sev'] = df_2020['total_dis_sev']*10000\n",
    "# df_2020['dm_sev'] = df_2020['dm_sev']*10000\n",
    "# df_2020['dm_inc'] = df_2020['dm_inc']*10000\n",
    "\n",
    "# df_2020['inc_class'] = 'low'\n",
    "# df_2020.loc[df_2020['dm_inc']>25,'inc_class']= 'high'\n",
    "    \n",
    "# df_2020['severity_class'] = 'low'\n",
    "# df_2020.loc[df_2020['dm_sev']>10,'severity_class']= 'high'\n",
    "\n",
    "# vis_2020 = add_vis(df_2020)\n",
    "\n",
    "\n",
    "# #2021\n",
    "# dfs_2021 = [img_to_df(dis_ras_21[i], cols) for i in np.arange(len(dis_ras_21))]\n",
    "# df_2021 = pd.concat(dfs_2021)\n",
    "\n",
    "# df_2021['total_dis_sev'] = df_2021['total_dis_sev']*10000\n",
    "# df_2021['dm_sev'] = df_2021['dm_sev']*10000\n",
    "# df_2021['dm_inc'] = df_2021['dm_inc']*10000\n",
    "\n",
    "# df_2021['inc_class'] = 'low'\n",
    "# df_2021.loc[df_2021['dm_inc']>25,'inc_class']= 'high'\n",
    "    \n",
    "# df_2021['severity_class'] = 'low'\n",
    "# df_2021.loc[df_2021['dm_sev']>10,'severity_class']= 'high'\n",
    "\n",
    "# vis_2021 = add_vis(df_2021)\n",
    "# vis_2021 = vis_2021[vis_2021['Date']!='20210804']\n",
    "\n",
    "# #2022\n",
    "# dfs_2022 = [img_to_df(dis_ras_22[i], cols) for i in np.arange(len(dis_ras_22))]\n",
    "# df_2022 = pd.concat(dfs_2022)\n",
    "\n",
    "# df_2022['total_dis_sev'] = df_2022['total_dis_sev']*10000\n",
    "# df_2022['dm_sev'] = df_2022['dm_sev']*10000\n",
    "# df_2022['dm_inc'] = df_2022['dm_inc']*10000\n",
    "\n",
    "# df_2022['inc_class'] = 'low'\n",
    "# df_2022.loc[df_2022['dm_inc']>25,'inc_class']= 'high'\n",
    "    \n",
    "# df_2022['severity_class'] = 'low'\n",
    "# df_2022.loc[df_2022['dm_sev']>10,'severity_class']= 'high'\n",
    "\n",
    "# vis_2022 = add_vis(df_2022)\n",
    "# vis_2022.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7834004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_rf(df, expl_vars, resp_var, SPLIT_RND_SEED):\n",
    "#     X = df[expl_vars]\n",
    "#     y = df[resp_var]\n",
    "    \n",
    "#     rus = RandomUnderSampler(random_state=2020)\n",
    "#     X_rus, y_rus = rus.fit_resample(X, y)\n",
    "\n",
    "# # Split dataset into training set and test set\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_rus, y_rus,\n",
    "#                                                     test_size=0.3, \n",
    "#                                                     random_state=SPLIT_RND_SEED,\n",
    "#                                                     stratify = y_rus)  # 70% training and 30% test\n",
    "#     mm = MinMaxScaler()\n",
    "#     X_train_scaled = mm.fit_transform(X_train)\n",
    "#     X_test_scaled = mm.transform(X_test)\n",
    "    \n",
    "    \n",
    "#     from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "#     # Modify with best parameters  \n",
    "#     rf = RandomForestClassifier()\n",
    "        \n",
    "        \n",
    "# #                                 n_estimators = 500, \n",
    "# #                                 oob_score=True, \n",
    "# #                                 #random_state=rand_state, # random number to be used, needed to reproduce the same result\n",
    "# #                                 verbose=False)\n",
    "    \n",
    "#     rf_model = rf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "#     y_pred = rf_model.predict(X_test_scaled)\n",
    "    \n",
    "#     from sklearn.metrics import accuracy_score\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "#     from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "#     prec, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "  \n",
    "    \n",
    "#     from sklearn.metrics import cohen_kappa_score\n",
    "        \n",
    "#     cohen_score = cohen_kappa_score(y_test, y_pred)    \n",
    "\n",
    "#     label_0 = np.unique(y_pred)[0]\n",
    "#     label_1 = np.unique(y_pred)[1]\n",
    "    \n",
    "#     metrics = {\n",
    "#         'cohen_kappa': [cohen_score], \n",
    "#         'accuracy_score': [accuracy],\n",
    "#         'precision {}'.format(label_0): [prec[0]],\n",
    "#         'precision {}'.format(label_1): [prec[1]],\n",
    "#         'recall {}'.format(label_0): [recall[0]],\n",
    "#         'recall {}'.format(label_1): [recall[1]],\n",
    "#         'fscore {}'.format(label_0): [fscore[0]],\n",
    "#         'fscore {}'.format(label_1): [fscore[1]],\n",
    "\n",
    "#     }\n",
    "#     metrics_df = pd.DataFrame(data=metrics)\n",
    "    \n",
    "#     return metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
